<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Willbroad</title>
    <link>https://example.com/post/</link>
    <description>Recent content in Projects on Willbroad</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Mar 2021 12:00:00 -0500</lastBuildDate><atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Project I: Market Basket Analysis</title>
      <link>https://example.com/post/chapter-8/</link>
      <pubDate>Thu, 14 Oct 2021 11:25:05 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-8/</guid>
      <description>Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. The apriori algorithm has been designed to operate on databases containing transactions, such as purchases by customers of a store. An itemset is considered as “frequent” if it meets a user-specified support threshold. For instance, if the support threshold is set to 0.5 (50%), a frequent itemset is defined as a set of items that occur together in at least 50% of all transactions in the database.</description>
    </item>
    
    <item>
      <title>Chapter II: Sentiment Analysis Project in Python</title>
      <link>https://example.com/post/chapter-2/</link>
      <pubDate>Sun, 10 Oct 2021 11:00:59 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-2/</guid>
      <description>Sentiment analysis is a the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer’s attitude towards a particular topic, product, etc. is positive, negative, or neutral.
I think this result from google dictionary gives a very succinct definition. I don’t have to re-emphasize how important sentiment analysis has become. So, here we will build a classifier on IMDB movie dataset using a Deep Learning technique called RNN.</description>
    </item>
    
    <item>
      <title>Project III: Interactive Dashboard project</title>
      <link>https://example.com/post/chapter-6/</link>
      <pubDate>Sat, 14 Aug 2021 11:25:05 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-6/</guid>
      <description>In this project, I have created a python interactive dashbaord with plotly Dash. Web based dashbaords are a great way to display and share information with others. Plotly Dash is the go-to library for creating interactive and beautiful web applications.
 Below are the steps involved. Exploring the dataset. Setting up python environment, I have used Pycharm Editor-community edition. Preparing to build the Dash app. Building the layout of the dashbaord.</description>
    </item>
    
    <item>
      <title>Project IV: Exploratory Data Analysis</title>
      <link>https://example.com/post/chapter-5/</link>
      <pubDate>Fri, 13 Aug 2021 11:15:58 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-5/</guid>
      <description>This is the critical process of performing initial investigations on data so as to discover patterns to spot anomalies to test hypothesis and to check assumptions with the help of summary statistics and graphical representations. Steps involved:
 Importing the required libraries for EDA Loading the data into the data frame Understanding the structure of dataframe and data types Checking the types of data Generating descriptive statistics of the data frame Indexing and retrieving data Grouping data Summary tables Dataframe transformation  Link to github repository</description>
    </item>
    
    <item>
      <title>Project V: Customer Segmentation in K-Mean Clustering</title>
      <link>https://example.com/post/chapter-3/</link>
      <pubDate>Sun, 11 Jul 2021 11:13:32 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-3/</guid>
      <description>The goal of this project is to group data points into distinct non-overlapping subgroups of customers to get a better understanding of them which in turn could be used to increase the revenue of the company. Steps involved:
 Import data and select features Build the model Visualizing the ELBOW method to get the optimal value of K Visualizing all the clusters Model interpretation  Link to github repository</description>
    </item>
    
    <item>
      <title>Project VI: Customer Churn Prediction in Python</title>
      <link>https://example.com/post/chapter-7/</link>
      <pubDate>Wed, 14 Apr 2021 11:25:05 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-7/</guid>
      <description>This project on Customer Churn prediction is about detecting which customers are likely to cancel a subscription to a service based on how they use the service. It is a critical prediction for many businesses because acquiring new clients often costs more than retaining existing ones. Below are the steps involved:
 Importing the libraries Loading the dataset Selecting relevant features Converting categorical columns to numeric ones Preprocessing the data Training a machine learning algorithm Evaluating the machine learning algorithm Evaluating the dataset features Conclusion and recommendation  Link to github repository</description>
    </item>
    
    <item>
      <title>Project VII: Time series analysis project</title>
      <link>https://example.com/post/chapter-4/</link>
      <pubDate>Fri, 12 Feb 2021 11:14:48 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-4/</guid>
      <description>Time series analysis is basically analyzing the data to find some pattern or trend over a certain period of time. After successfully analyzing the data, you have to forecast future trends/patterns. The nature of time series analysis is more identical to regression analysis, but here the data is time-dependent. In regression, it is assumed that the variables must be independent of each other. So, mere regression analysis can not be applied to time series data.</description>
    </item>
    
    <item>
      <title>Project VIII: Logistic regression</title>
      <link>https://example.com/post/chapter-1/</link>
      <pubDate>Tue, 09 Feb 2021 10:58:08 -0400</pubDate>
      
      <guid>https://example.com/post/chapter-1/</guid>
      <description>This is regression analysis project that is conducted when the dependent variable is dichotomous (binary). Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.
 Checking that the target variable is binary Checking and taking care of missing values in the dataset Converting categorical variables to a dummy indicator Checking for independence between features Checking that the dataset size is sufficient Deploying and evaluating logistic Regression model Model Evaluation Classification report without cross-validation K-fold cross-validation &amp;amp; confusion matrices * Make a test prediction  Link to github repository</description>
    </item>
    
  </channel>
</rss>
